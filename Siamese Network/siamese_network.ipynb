{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.make_pairs import make_pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data For Siamese Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = r'C:\\Users\\jands\\Market-1501-v15.09.15\\bounding_box_train'\n",
    "val_data_dir = r'C:\\Users\\jands\\Market-1501-v15.09.15\\bounding_box_val'\n",
    "\n",
    "file_paths_train = tf.data.Dataset.list_files(train_data_dir + '/*.jpg')\n",
    "file_paths_val = tf.data.Dataset.list_files(val_data_dir + '/*.jpg')\n",
    "\n",
    "# Define the function to extract the label from the file name\n",
    "# works for my specific directory path...\n",
    "def extract_label(file_path):\n",
    "    label = tf.strings.split(file_path, '_')\n",
    "    label = tf.strings.split(label, '\\\\')\n",
    "    return int(label[2][1])\n",
    "\n",
    "def read_and_decode(file_path):\n",
    "    label = extract_label(file_path)\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "print(\"[INFO] loading data...\")\n",
    "\n",
    "dataset_train = [read_and_decode(file) for file in file_paths_train]\n",
    "dataset_val = [read_and_decode(file) for file in file_paths_val]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "subplot_pos = 1\n",
    "\n",
    "for image, label in dataset_train[:9]:\n",
    "  ax = plt.subplot(1, 9, subplot_pos)\n",
    "  subplot_pos += 1\n",
    "  plt.imshow(image)\n",
    "  plt.title(label)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "print(\"IMAGE SHAPE: \", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label for image, label in dataset_train]\n",
    "unique_labels = np.unique(np.array(labels))\n",
    "\n",
    "idxs = [np.where(labels == unique_label)[0] for unique_label in unique_labels]\n",
    "\n",
    "for unique_label in unique_labels:\n",
    "    idxs = np.where(labels == unique_label)[0]\n",
    "    print(f\"{unique_label} => {len(idxs)} : {idxs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_x, train_pair_y = make_pairs(dataset_train)\n",
    "val_pair_x, val_pair_y = make_pairs(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 9)\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0)\n",
    "j = 0\n",
    "\n",
    "for img_1, img_2 in train_pair_x[:9]:\n",
    "  axes[0, j].imshow(img_1)\n",
    "  axes[1, j].imshow(img_2)\n",
    "  axes[0, j].set_title(train_pair_y[j])\n",
    "  axes[0, j].set_axis_off()\n",
    "  axes[1, j].set_axis_off()\n",
    "  j += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from utils.euclidean_distance import euclidean_distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the image size for all the images in The Market Dataset is 128x64\n",
    "IMG_SHAPE = (128, 64, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "feature_extractor = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] building model...\")\n",
    "img_1 = Input(shape=IMG_SHAPE)\n",
    "img_2 = Input(shape=IMG_SHAPE)\n",
    "\n",
    "features_1 = feature_extractor(img_1)\n",
    "features_2 = feature_extractor(img_2)\n",
    "distance = Lambda(euclidean_distance)([features_1, features_2])\n",
    "pooling = GlobalAveragePooling2D()(distance)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(pooling)\n",
    "model = Model(inputs=[img_1, img_2], outputs=outputs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "tensoboard_dir = r\"C:\\Users\\jands\\Project_Shaman\\Siamese Network\\logs\\tensorboard\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensoboard_dir, histogram_freq=1)\n",
    "\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[train_pair_x[:, 0], train_pair_x[:, 1]], train_pair_y[:],\n",
    "\tvalidation_data=([val_pair_x[:, 0], val_pair_x[:, 1]], val_pair_y[:]),\n",
    "\tbatch_size=BATCH_SIZE, \n",
    "\tepochs=EPOCHS,\n",
    "\tcallbacks=[tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualized data from training can be also found in tensorboard\n",
    "from utils.plot_training import plot_training\n",
    "path = \"logs/training_plot.png\"\n",
    "print(\"[INFO] plotting training history...\")\n",
    "plot_training(history, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/siamese_network.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_9_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412e3301929c0b4e6dbd1b029bf68da7d37f7d3790d9ed7946c87cf9399551e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
